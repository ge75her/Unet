{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet\n",
    "This is a project about Image Segmentation. The dataset of the project is from DRIVE,a Retinal Vessel Segmentation datasset, and Unet network is used to finish this task.\n",
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:16.613055Z",
     "iopub.status.busy": "2022-02-04T19:11:16.612117Z",
     "iopub.status.idle": "2022-02-04T19:11:18.473129Z",
     "shell.execute_reply": "2022-02-04T19:11:18.472134Z",
     "shell.execute_reply.started": "2022-02-04T19:11:16.612947Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "def read_image(train):\n",
    "    path=''\n",
    "    if train:\n",
    "        img_dir=path+'training/images/'\n",
    "        label_dir=path+'training/1st_manual/'\n",
    "        img=os.listdir(img_dir)\n",
    "        label=os.listdir(label_dir)\n",
    "        images=[img_dir+i for i in img]\n",
    "        labels=[label_dir+i for i in label]\n",
    "    else:\n",
    "        img_dir=path+'test/images/'\n",
    "        label_dir=path+'test/1st_manual/'\n",
    "        img=os.listdir(img_dir)\n",
    "        label=os.listdir(label_dir)\n",
    "        images=[img_dir+i for i in img]\n",
    "        labels=[label_dir+i for i in label]\n",
    "    return images,labels\n",
    "def crop(img,size):\n",
    "    h,w,c=img.shape\n",
    "    _w,_h=size\n",
    "    # h w ratio not change\n",
    "    scale=min(_h/h,_w/w)\n",
    "    h=int(h*scale)\n",
    "    w=int(w*scale)\n",
    "    img=cv2.resize(img,(w,h),interpolation=cv2.INTER_CUBIC)\n",
    "    top=(_h-h)//2\n",
    "    left=(_w-w)//2\n",
    "    bottom=_h-h-top\n",
    "    right=_w-w-left\n",
    "    #create a new img with color black on edge\n",
    "    new_img=cv2.copyMakeBorder(img,top,bottom,left,right,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "    return new_img\n",
    "def image_transform(data,label,size):\n",
    "    data=crop(data,size)\n",
    "    label=crop(label,size)\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "    data=transform(data)\n",
    "    label=transform(label)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:18.474907Z",
     "iopub.status.busy": "2022-02-04T19:11:18.474653Z",
     "iopub.status.idle": "2022-02-04T19:11:18.487203Z",
     "shell.execute_reply": "2022-02-04T19:11:18.485596Z",
     "shell.execute_reply.started": "2022-02-04T19:11:18.474878Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Drive(Dataset):\n",
    "    def __init__(self,train,h,w,transform):\n",
    "        self.h=h\n",
    "        self.w=w\n",
    "        self.transform=transform\n",
    "        if train:\n",
    "            self.data_list, self.label_list=read_image(train=True)\n",
    "        else:\n",
    "            self.data_list,self.label_list=read_image(train=False)\n",
    "    def __getitem__(self,index):\n",
    "        img_dir=self.data_list[index]\n",
    "        label_dir=self.label_list[index]\n",
    "        img=cv2.imread(img_dir)\n",
    "        _,label=cv2.VideoCapture(label_dir).read()\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        label=cv2.cvtColor(label,cv2.COLOR_BGR2RGB)\n",
    "        img,label=self.transform(img,label,(self.h,self.w))\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:18.489144Z",
     "iopub.status.busy": "2022-02-04T19:11:18.488778Z",
     "iopub.status.idle": "2022-02-04T19:11:18.519570Z",
     "shell.execute_reply": "2022-02-04T19:11:18.518760Z",
     "shell.execute_reply.started": "2022-02-04T19:11:18.489098Z"
    }
   },
   "outputs": [],
   "source": [
    "h=572\n",
    "w=572\n",
    "train_set=Drive(train=True,h=h,w=w,transform=image_transform)\n",
    "train_loader=DataLoader(train_set,batch_size=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:18.522123Z",
     "iopub.status.busy": "2022-02-04T19:11:18.521736Z",
     "iopub.status.idle": "2022-02-04T19:11:18.540735Z",
     "shell.execute_reply": "2022-02-04T19:11:18.539594Z",
     "shell.execute_reply.started": "2022-02-04T19:11:18.522076Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Doubleconv(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Sequential(nn.Conv2d(in_channel,out_channel,kernel_size=3,padding=1),\n",
    "                               nn.BatchNorm2d(out_channel),\n",
    "                               nn.Dropout(0.3),\n",
    "                               nn.ReLU(inplace=True),\n",
    "                               nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1),\n",
    "                               nn.BatchNorm2d(out_channel),\n",
    "                               nn.Dropout(0.4),\n",
    "                               nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "class Down(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.maxpool=nn.Sequential(nn.MaxPool2d(2,2),\n",
    "                                  Doubleconv(in_channel,out_channel))\n",
    "    def forward(self,x):\n",
    "        return self.maxpool(x)\n",
    "class Up(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up=nn.Upsample(scale_factor=2,mode='bilinear',align_corners=True)\n",
    "        else:\n",
    "            self.up=nn.ConvTranspose2d(n_channel//2,in_channel//2,kernel_size=2,stride=2)\n",
    "        self.conv=Doubleconv(in_channel,out_channel)\n",
    "    def forward(self,x1,x2):\n",
    "        x1=self.up(x1)\n",
    "        diffY=torch.tensor([x2.size()[2]-x1.size()[2]])\n",
    "        diffX=torch.tensor([x2.size()[3]-x1.size()[3]])\n",
    "        x1=nn.functional.pad(x1,[diffX//2,diffX-diffX//2,diffY//2,diffY-diffY//2])\n",
    "        x=torch.cat([x2,x1],dim=1)\n",
    "        return self.conv(x)\n",
    "class Outconv(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super(Outconv,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channel,out_channel,kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:21.290696Z",
     "iopub.status.busy": "2022-02-04T19:11:21.290374Z",
     "iopub.status.idle": "2022-02-04T19:11:21.302117Z",
     "shell.execute_reply": "2022-02-04T19:11:21.301037Z",
     "shell.execute_reply.started": "2022-02-04T19:11:21.290656Z"
    }
   },
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_channels,bilinear=True):\n",
    "        super(Unet,self).__init__()\n",
    "        self.n_channel=n_channels\n",
    "        self.bilinear=bilinear\n",
    "        self.inc=Doubleconv(n_channels,64)\n",
    "        self.down1=Down(64,128)\n",
    "        self.down2=Down(128,256)\n",
    "        self.down3=Down(256,512)\n",
    "        self.down4=Down(512,512)\n",
    "        #out_channel= next step in_channel\n",
    "        self.up1=Up(1024,256,bilinear)\n",
    "        self.up2=Up(512,128,bilinear)\n",
    "        self.up3=Up(256,64,bilinear)\n",
    "        self.up4=Up(128,64,bilinear)\n",
    "        self.outc=Outconv(64,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x1=self.inc(x)\n",
    "        x2=self.down1(x1)\n",
    "        x3=self.down2(x2)\n",
    "        x4=self.down3(x3)\n",
    "        x5=self.down4(x4)\n",
    "        x=self.up1(x5,x4)\n",
    "        x=self.up2(x,x3)\n",
    "        x=self.up3(x,x2)\n",
    "        x=self.up4(x,x1)\n",
    "        x=self.outc(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T19:11:21.307240Z",
     "iopub.status.busy": "2022-02-04T19:11:21.306590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 572, 572])\n"
     ]
    }
   ],
   "source": [
    "model=Unet(n_channels=3)\n",
    "cri=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-4,weight_decay=1e-8,momentum=0.9)\n",
    "best_loss=0.0\n",
    "for epoch in range(10):\n",
    "    total_loss=0.0\n",
    "    for data,label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        print(label.shape)\n",
    "        output=model(data)\n",
    "        print(output.shape)\n",
    "        batch_loss=cri(output,label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+=batch_loss.item()\n",
    "        \n",
    "    print('epoch:',epoch,'loss:',total_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorchgpu]",
   "language": "python",
   "name": "conda-env-.conda-pytorchgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
